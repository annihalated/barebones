---
title: Against Searching for Saints
permalink: /saints/
description: "in defense of paying people to do things • incentives solve principal-agent problems • motivated agents exist but are unevenly distributed and hard to identify"
---

Adam Mastroianni [argues](https://www.experimental-history.com/p/startling-differences-between-humans) that we are using incentives poorly. His case has two parts.

First, he argues that we are operating based on a flawed theory of human motivation. He argues that people are neither jukeboxes (who only do good things when incentivised to do so) nor secret criminals (who will actively do bad things unless incentivised to do good things). Instead, we must recognise that intrinsic motivations and interests are powerful. In support of his criticism of incentive theory, he offers many examples of situations where people game incentives and obtain rewards without actually doing the behaviour that is incentivised.  

Second, he has a positive case about how we should use incentives. He thinks that, instead of using incentives to *modify* behaviour, we should find the people who already exhibit the desired behaviour and support them. We should focus on finding good people (who do not need to be incentivised or coerced) and firing the bad people (who can only be redeemed through lengthy processes).

In Adam's words: 

> The best way to use incentives, then, is to:
>
> 1\) find the people who already want what you want
>
> 2\) help them survive

## Some basics

Incentive theory addresses solutions to a category of principal-agent problems. This is how [Sappington (1991)](https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.5.2.45) opens: 

> "If you want something done right, do it yourself." This age-old maxim has some of the major concerns of modern "incentive theory" at its heart. Incentive theory, however, generally focuses on tasks that are too complicated or too costly to do oneself. Thus, the "principal" is obliged to hire an "agent" with specialized skills or knowledge to perform the task in question. The central concern is how the principal can best motivate the agent to perform as the principal would prefer, taking into account the difficulties in monitoring the agent's activities.

This principal-agent metaphor, the literature tells me, has broad application. Incentives by governments, by regulators, by employers --- you can apply the principal-agent model to all of them and mostly understand incentive theory. 

Marginal Revolution University's [video](https://www.youtube.com/watch?v=kd2r3ARB2tk) on principal-agent problems gives you the example of trying to get your car repaired. You don't know how much your car repairs should cost, or what kinds of repairs the car needs. Let's say the mechanic is incentivised to maximise his fee, and your incentive is to get the car repaired at the lowest long-run cost. Incentive theory and contract design are about trying to build contracts and arrangements which ensure that your interests are aligned. 

## Motivated agents

Let's get back to Adam's case. It skips the principal-agent problem, because Adam's principal has already hired someone with aligned incentives ("good people", "people who already want what you want"). These people, to be sure, exist in the incentive theory literature, and they are called "motivated agents" who are "characterised by increasing their effort, if their work generates not only a monetary return for them but also a benefit for a mission they support." [(Koppel and Regner 2019)](https://www.sciencedirect.com/science/article/abs/pii/S2214804319300084)

### 1) They are not evenly distributed

<figure>
<img class="invert" src="/assets/img/normal.png" />
<figcaption>A normal distribution.</figcaption>
</figure>

The natural distribution of interests produces guys who read Sartre at a coffee shop with a Marlboro Red hanging languorously from his lips more often than it produces people willing to work in trial courts. Our motivations and intrinsic interests are not always socially productive: playing Factorio, scrolling through Instagram, writing poetry about owls. I thought the point of incentives was to allocate ourselves to socially useful tasks, to transmute our interests in memorising anime trivia into computer programs and healthcare units.

I know normal distributions are an oversimplification, but I think they're helpful as a way of thinking about this. The left tail of the normal distribution for "passion" consists of guys who have, well, very little passion. They want to sit at home all day watching TV or scrolling through Instagram. 

The upper, or right, tail of the normal distribution consists of people Adam wants to hire. They are, in my life, the underpaid researchers who could make much more money at any given point in time by switching from physics or microbiology to building mediocre widgets for enterprise software systems - but *simply will not*. They are, in the lives of some of my friends, excellent doctors who work in the government system who could make *much more money* working in a private hospital.  

The vast majority of people, however, are in the middle. We are neither secret criminals nor jukeboxes. We are morally grubby; we like money and dislike discomfort. We care about status and the opinions of our peers. We also *have* passions, not in a "fanatical religious devotion" sense, but in a "I like going to church" sense. In other words, we are human.

In many public services, you will find many people who see themselves as producing a collective good. They work hard, partly because they need to earn a living, but also because they believe the work they do produces a collective good. But it's harder to find motivated agents in areas where you are not producing a collective good. 

This is about passion, not skill. Even if you find a person who is a *great* engineer, that does not mean they will care about the particular tasks you have for them. Not all jobs evoke burning passion, and extreme dedication (thankfully) isn't required in most jobs. Sure, we need to hire constitutional law theorists, but we also need to hire drivers and receptionists and mechanics and waiters. You have to deal with most people. You have to deal with bad apples. What are you going to do, give up? 

### 2) They are hard to identify

Now, "picking the right people" as a solution understates the problem of finding them. Given perfect information, you would, of course, try to hire agents who would "perform as the principal would prefer" or "who already want what you want." The problem is that people *lie* about being motivated agents. Especially if, like Adam, you put up a big sign saying "*I want to hire motivated agents.*" In individual interviews, distinguishing between truths and falsehoods about people's internal motivations isextremely difficult. At scale, it is practically impossible

I know this from constitutional theory, which I understand much better than economics. Adam quotes Dune to say that "[g]ood governance never depends upon laws, but upon the personal qualities of those who govern." This is correct. Except that the [major developments in constitutional theory](https://nihalsahu.substack.com/p/authority) over the last few centuries have been about discovering that it is *impossible* for any system of government to reliably pick the "right leaders". As I wrote [a week or two ago](https://nihalsahu.substack.com/p/authority):

> In 1787, the Americans [...] had a more structural, a more sophisticated theory of the human desire for power, of ego and ambition. They created three strong branches of government which tended naturally to conflict among themselves, but gave each of them "the necessary constitutional means and personal motives to resist encroachments of the others" [(Federalist No. 51)](https://avalon.law.yale.edu/18th_century/fed51.asp). They made the "provision for defense" commensurate to the "danger of attack." They desired that "[t]he interest of the man . . . be connected with the constitutional rights of the place.

In other words, they used incentives and systems thinking! The last line about the "interests of the man" being connected with the "constitutional rights of the place" are literally about incentive compatibility. 

There's a few hundred years of constitutional theory dealing with the problem of preventing leaders from becoming tyrants, and then there's Adam, saying "I would simply not elect tyrants." 

There's a few hundred years of economic theory dealing with principal-agent problems and the difficulty of aligning incentives with imperfect information, and then there's Adam, saying "I would simply hire the right people." 

## Morality, motivations, and rewards

Adam's people are devoted already, which means that, for some purposes, they leave the universe of people we need to *motivate*. A lot of people are passionate about medicine because one of their relatives died on an operating table. We are glad they channel their rage in this manner. *We are no longer thinking about them*. They will plug away at the problem, and we are happy about that. 

Incentives have a role in getting a lot of people from "has interest in medicine because watches House MD" to "heart surgeon". A passing interest does not survive gruelling years of medical school or an aversion to cutting open human beings. This is where I cue in [Patrick McKenzie](https://x.com/patio11/status/1745337977591501009):

<img alt="image of tweets from patrick mckenzie: https://x.com/patio11/status/1745337977591501009" class="invert" src="/assets/img/patio.png" />

Are "interests" and "shared goals" enough to make someone stay in medical school? Is it enough to make them want to live in India's most deprived villages, where their patients are?

There are not enough people who *want* to do this and are willing to be trained to do this, i.e. we have a scarcity of doctors. This scarcity is reflected in the price we are willing to pay for their services. What an incentive does is find everyone who could be plausibly made to apply their minds to a problem and gives them a reason to do so. The fact that the Bureau of Labor Statistics says doctors in the US make $239k is a signal that finds everyone who *might* be persuaded to go into medicine and gives them 239,000 reasons to do so.

And so we manufacture doctors by the tens of thousands. And as Patrick says, if one day, we realise we could realise many more units of healthcare by simply pressing a button and making the doctors redundant, we will press that button with a ruthless mind for efficiency.

There is an understandable, moral, good hearted temptation to reward people who love medicine instead of incentivising our fellow grubby humans to get through medical school. This is misguided self-righteousness. The doctors who don't care about the incentive are the upper tail of the normal distribution. But for the rest of humanity, which consists of grubby little humans, incentives matter at the margin. They might or might not be *better* doctors than the saints, but there are more of them, and they produce units of healthcare in a world where units of healthcare are scarce.  

We, as a society, are not motivated by finding saints and rewarding them. The saints will produce healthcare units anyway. We are motivated to ensure the production of healthcare units, and therefore, we are motivated to pay the hundreds of thousands of potential doctors who will cure diseases, even if they do not, at night, dream about clinical technique or stay up worrying about the suffering of a dying patient. 

This might seem a little unfair. Why are we handing out carrots to the people for whom the carrots are the objective, as opposed to the people for whom *medicine* is the objective? But being a little unfair is alright if you aren't in the business of moral redemption. 

We are not interested in 'rewarding only the truly deserving' or creating Valhalla. We are interested in creating good outcomes. May we always be clear-eyed enough to tell the difference. 

<small>*Thanks to [Pranav Agarwal](https://x.com/AgroPrawn) for his detailed comments and contributed paragraphs which improved this essay considerably. My thanks and apologies to [Judah](https://x.com/joodalooped), who sent me Adam's piece two months ago, suggested I write a response "in a couple of hours", and helped me to finally get this out.*</small>
